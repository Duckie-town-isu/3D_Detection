{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from mmdet3d.evaluation.metrics import nuscenes_metric as nus_metric\n",
    "from mmdet3d.evaluation.metrics.nuscenes_metric import output_to_nusc_box\n",
    "import json \n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.data_classes import Box\n",
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "import operator\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.eval.detection.config import config_factory\n",
    "from nuscenes.eval.detection.evaluate import NuScenesEval\n",
    "from classes import cls_attr_dist, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_val_tokens = [\n",
    "    '3e8750f331d7499e9b5123e9eb70f2e2', \n",
    "    '3950bd41f74548429c0f7700ff3d8269', \n",
    "    'c5f58c19249d4137ae063b0e9ecd8b8e', \n",
    "    '700c1a25559b4433be532de3475e58a9', \n",
    "    '747aa46b9a4641fe90db05d97db2acea', \n",
    "    'f4f86af4da3b49e79497deda5c5f223a', \n",
    "    '6832e717621341568c759151b5974512', \n",
    "    'c59e60042a8643e899008da2e446acca', \n",
    "    'fa65a298c01f44e7a182bbf9e5fe3697', \n",
    "    'a98fba72bde9433fb882032d18aedb2e', \n",
    "    'b6b0d9f2f2e14a3aaa2c8aedeb1edb69', \n",
    "    '796b1988dd254f74bf2fb19ba9c5b8c6', \n",
    "    '0d0700a2284e477db876c3ee1d864668', \n",
    "    'de7593d76648450e947ba0c203dee1b0', \n",
    "    'f753d3f87e5b40af87ff2cbf7c8e7082', \n",
    "    'b22fa0b3c34f47b6a360b60f35d5d567', \n",
    "    '0a0d6b8c2e884134a3b48df43d54c36a', \n",
    "    '8e9c2cba0ee74056aa3746e8391d54a9', \n",
    "    'fdc39b23ab4242eda6ec5e1e6574fe33', \n",
    "    '9ee4020153674b9e9943d395ff8cfdf3', \n",
    "    '5b03af7a953245b5a3b23191ed4da62a', \n",
    "    'd0ecf474e0e64950aa265cd44b9c9d75', \n",
    "    '456ec36cb4a44ca78f36fbd90c0c34fa', \n",
    "    '6bfd42cf0aba4f1a94ec11fa43e2dd92', \n",
    "    '0af0feb5b1394b928dd13d648de898f5', \n",
    "    '61d9340c5ad8418dafe7a4af1b96e6b9', \n",
    "    '9e7683e8586542a1b6032980c45f15ce', \n",
    "    'cc57c1ea80fe46a7abddfdb15654c872', \n",
    "    '4cf5d6c3f6ab42aab23f67b5a9782d1a', \n",
    "    '6d9984d09d52479e837da2fd09e192cc', \n",
    "    '38a28a3aaf2647f2a8c0e90e31267bf8', \n",
    "    '6402fd1ffaf041d0b9162bd92a7ba0a2', \n",
    "    'ce94ef7a0522468e81c0e2b3a2f1e12d', \n",
    "    '9fcdc52b791045e99c623c5fc643331f', \n",
    "    '1c9a906c40f6417bbe1cea06d6e55501', \n",
    "    'a771effa2a2648d78096c3e92b95b129', \n",
    "    'b9ea04a6121d4a8bb00199b885aa5ef0', \n",
    "    '87e772078a494d42bd34cd16172808bc', \n",
    "    'f40544fd4f5d42abbcfa948eeaf86850', \n",
    "    '281b92269fd648d4b52d06ac06ca6d65', \n",
    "    'b5989651183643369174912bc5641d3b', \n",
    "    '0bb62a68055249e381b039bf54b0ccf8', \n",
    "    '07fad91090c746ccaa1b2bdb55329e20', \n",
    "    'ae5004bf4ebb4db0a84cb3c27bd398d1', \n",
    "    'ac8b4d49731d43289579f014cb7c97ef', \n",
    "    'c1eed31234b94e9f8e22fbf3428b0ac2', \n",
    "    'edba7d0cf1c64d2a9c8a5ebddab507a9', \n",
    "    'a5afebb0aa5e4d7c95665788ce51ec58', \n",
    "    '5b7cb170eee6468aa1fdbd3abcf63c5a', \n",
    "    'd8251bbc2105497ab8ec80827d4429aa', \n",
    "    '048a45dd2cf54aa5808d8ccc85731d44', \n",
    "    '858a1ece22cf45d9bc71e42336604b78', \n",
    "    '372725a4b00e49c78d6d0b1c4a38b6e0', \n",
    "    '61a7bd24f88a46c2963280d8b13ac675', \n",
    "    '609d5177362340458a3bfd4949cd1e64', \n",
    "    'b1303058fa624645b753d7283d70de45', \n",
    "    'a19a80c905674faab7203a3a4e0f5246', \n",
    "    'b6c420c3a5bd4a219b1cb82ee5ea0aa7', \n",
    "    '8092909473464f80b9f791a4d31ddcb8', \n",
    "    'e174cb43655f49dab7ffa27b973670e3', \n",
    "    '6ff9723a60bf4e14b328b3b19f04dc32', \n",
    "    '06be0e3b665c44fa8d17d9f4770bdf9c', \n",
    "    '9150678870764c1b87a649a25939c61b', \n",
    "    '8573a885a7cb41d185c05029eeb9a54e', \n",
    "    '55c258972acb4300a3a6077a531ab050', \n",
    "    '44237858a539457da65822bfcf58c414', \n",
    "    '8cd36e9531fb4eba8e6ac1d666c4641c', \n",
    "    '7bebe3c9be714f02837f8617c56df122', \n",
    "    '4b894442c95141f9affd731d9da7b43c', \n",
    "    'e00dc15130dc44e796687baadd076ae4', \n",
    "    'e63b83b436a0479db7362338cdfab118', \n",
    "    'c567f9b8e9f34817acdc9c49d791c557', \n",
    "    '8e352d4a6c6f40c8ad4f10a3d2c3f158', \n",
    "    '841dd6709e9b4d7c9d6bf888f1fe6d7e', \n",
    "    'e54b784a608644a2804fcf800c7499f7', \n",
    "    'a1289b27ca1d41deb6fc982be9a3d03c', \n",
    "    'e6e877f31dd447199b56cae07f86daad', \n",
    "    'cb4e6195faad467094fbd4d0a9e960e9', \n",
    "    '7f594234e8034228b1a7d727f1981e09', \n",
    "    '9cdbf5ff7f294549aea0a4307e5d104a', \n",
    "    'b4ff30109dd14c89b24789dc5713cf8c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.416 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.2 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "backend_args = None\n",
    "home_dir = str(Path.home())\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot = f\"{home_dir}/software/mmdetection3d/data/nuscenes\")\n",
    "dataroot = f\"{home_dir}/software/mmdetection3d/data/nuscenes/\"\n",
    "out_dir = f\"{home_dir}/nuscenes_dataset/inference_results_mini\"\n",
    "preds_dir = os.path.join(out_dir, \"preds\")\n",
    "ann_file=dataroot + 'nuscenes_infos_val.pkl'\n",
    "metric='bbox'\n",
    "\n",
    "pcd_path = f\"{home_dir}/software/mmdetection3d/data/nuscenes/samples/LIDAR_TOP/\"\n",
    "mmdet_path = f\"{home_dir}/software/mmdetection3d\"\n",
    "pcd_list = os.listdir(pcd_path)\n",
    "\n",
    "# Config and model:\n",
    "configs_path = \"configs/pointpillars/pointpillars_hv_fpn_sbn-all_8xb4-2x_nus-3d.py\"\n",
    "checkpoint_path = \"checkpoints/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20210826_104936-fca299c1.pth\"\n",
    "\n",
    "# Instantiate evaluator:\n",
    "evaluator = nus_metric.NuScenesMetric(dataroot, ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified PCDet functions:\n",
    "# Box conversion\n",
    "def boxes_lidar_to_nusenes(det_info):\n",
    "    boxes3d = det_info['bboxes_3d']\n",
    "    scores = det_info['scores_3d']\n",
    "    labels = det_info['labels_3d']\n",
    "\n",
    "    box_list = []\n",
    "    for k in range(boxes3d.shape[0]):\n",
    "        quat = Quaternion(axis=[0, 0, 1], radians=boxes3d[k, 6])\n",
    "        velocity = (*boxes3d[k, 7:9], 0.0) if boxes3d.shape[1] == 9 else (0.0, 0.0, 0.0)\n",
    "        box = Box(\n",
    "            boxes3d[k, :3],\n",
    "            boxes3d[k, [4, 3, 5]],  # wlh\n",
    "            quat, label=labels[k], score=scores[k], velocity=velocity,\n",
    "        )\n",
    "        box_list.append(box)\n",
    "    return box_list\n",
    "\n",
    "def lidar_nusc_box_to_global(nusc, boxes, sample_token):\n",
    "    s_record = nusc.get('sample', sample_token)\n",
    "    sample_data_token = s_record['data']['LIDAR_TOP']\n",
    "\n",
    "    sd_record = nusc.get('sample_data', sample_data_token)\n",
    "    cs_record = nusc.get('calibrated_sensor', sd_record['calibrated_sensor_token'])\n",
    "    sensor_record = nusc.get('sensor', cs_record['sensor_token'])\n",
    "    pose_record = nusc.get('ego_pose', sd_record['ego_pose_token'])\n",
    "\n",
    "    data_path = nusc.get_sample_data_path(sample_data_token)\n",
    "    box_list = []\n",
    "    for box in boxes:\n",
    "        # Move box to ego vehicle coord system\n",
    "        box.rotate(Quaternion(cs_record['rotation']))\n",
    "        box.translate(np.array(cs_record['translation']))\n",
    "        # Move box to global coord system\n",
    "        box.rotate(Quaternion(pose_record['rotation']))\n",
    "        box.translate(np.array(pose_record['translation']))\n",
    "        box_list.append(box)\n",
    "    return box_list\n",
    "\n",
    "def transform_det_annos_to_nusc_annos(det_annos, nusc):\n",
    "    nusc_annos = {\n",
    "        'results': {},\n",
    "        'meta': None,\n",
    "    }\n",
    "\n",
    "    for det in det_annos:\n",
    "        annos = []\n",
    "        try:\n",
    "            box_list = boxes_lidar_to_nusenes(det)\n",
    "            box_list = lidar_nusc_box_to_global(\n",
    "                nusc=nusc, boxes=box_list, sample_token=det['metadata']['token']\n",
    "            )\n",
    "        except:\n",
    "            print(\"TypeError in transform_det_annos_to_nusc_annos: string indices must be integers\")\n",
    "        for k, box in enumerate(box_list):\n",
    "            name = det['name'][k]\n",
    "            if np.sqrt(box.velocity[0] ** 2 + box.velocity[1] ** 2) > 0.2:\n",
    "                if name in ['car', 'construction_vehicle', 'bus', 'truck', 'trailer']:\n",
    "                    attr = 'vehicle.moving'\n",
    "                elif name in ['bicycle', 'motorcycle']:\n",
    "                    attr = 'cycle.with_rider'\n",
    "                else:\n",
    "                    attr = None\n",
    "            else:\n",
    "                if name in ['pedestrian']:\n",
    "                    attr = 'pedestrian.standing'\n",
    "                elif name in ['bus']:\n",
    "                    attr = 'vehicle.stopped'\n",
    "                else:\n",
    "                    attr = None\n",
    "            attr = attr if attr is not None else max(\n",
    "                cls_attr_dist[name].items(), key=operator.itemgetter(1))[0]\n",
    "            nusc_anno = {\n",
    "                'sample_token': det['metadata']['token'],\n",
    "                'translation': box.center.tolist(),\n",
    "                'size': box.wlh.tolist(),\n",
    "                'rotation': box.orientation.elements.tolist(),\n",
    "                'velocity': box.velocity[:2].tolist(),\n",
    "                'detection_name': name,\n",
    "                'detection_score': box.score,\n",
    "                'attribute_name': attr\n",
    "            }\n",
    "            if det['scores_3d'][k] >= 0.6:\n",
    "                annos.append(nusc_anno)\n",
    "\n",
    "        nusc_annos['results'].update({det[\"metadata\"][\"token\"]: annos})\n",
    "\n",
    "    return nusc_annos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_token_dict():\n",
    "    \"\"\"\n",
    "    Constructs a dictionary mapping filenames to lidar and sample tokens\n",
    "    \"\"\"\n",
    "    token_dict = dict()\n",
    "    for scene in nusc.scene:\n",
    "        sample_token = scene['first_sample_token']\n",
    "        sample = nusc.get('sample', sample_token)\n",
    "        lidar_data = nusc.get('sample_data', sample['data'][\"LIDAR_TOP\"])\n",
    "        while sample['next'] != \"\":\n",
    "            filename = lidar_data['filename']\n",
    "            file_str = filename[filename.rfind(\"/\")+1:].replace(\"bin\", \"json\")\n",
    "            token_dict[file_str] = {\"lidar_token\": lidar_data['token'], \"sample_token\": lidar_data['sample_token']}\n",
    "            sample = nusc.get(\"sample\", sample['next'])\n",
    "            lidar_data = nusc.get('sample_data', sample['data'][\"LIDAR_TOP\"])\n",
    "        \n",
    "        filename = lidar_data['filename']\n",
    "        file_str = filename[filename.rfind(\"/\")+1:].replace(\"bin\", \"json\")\n",
    "        token_dict[file_str] = {\"lidar_token\": lidar_data['token'], \"sample_token\": lidar_data['sample_token']}\n",
    "\n",
    "    with open(\"token_dict_mini.json\", 'w') as f:\n",
    "        json.dump(token_dict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_token(fn):\n",
    "    with open(\"token_dict_mini.json\", 'r') as f:\n",
    "        token_dict = json.load(f)\n",
    "    sample_token = token_dict[fn]['sample_token']\n",
    "    f.close()\n",
    "    return sample_token\n",
    "\n",
    "# Read json file:\n",
    "def read_preds_file(fn):\n",
    "    full_fn = os.path.join(preds_dir, fn)\n",
    "    with open(full_fn, 'r') as f:\n",
    "        result = json.load(f)\n",
    "        result['bboxes_3d'] = torch.Tensor(result['bboxes_3d']).numpy()\n",
    "        result['scores_3d'] = torch.Tensor(result['scores_3d']).numpy()\n",
    "        class_labels = [class_names[k] for k in result['labels_3d']]\n",
    "        result['labels_3d'] = torch.Tensor(result['labels_3d']).numpy()\n",
    "        sample_token = dict()\n",
    "        sample_token['token'] = get_sample_token(fn)\n",
    "        result.update({'metadata':sample_token})\n",
    "        result.update({'name':class_labels})\n",
    "        \n",
    "    f.close()\n",
    "    return result\n",
    "\n",
    "def read_results():\n",
    "    \"\"\"\n",
    "    Reads the results from prediction files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the processed prediction data.\n",
    "    \"\"\"\n",
    "    preds_fn = os.listdir(preds_dir)\n",
    "    results = []\n",
    "    count = 1\n",
    "    for fn in preds_fn:\n",
    "        if count%1000 == 0:\n",
    "            print(\"Read results count: \", str(count))\n",
    "        results.append(read_preds_file(fn))\n",
    "        count += 1\n",
    "    return results\n",
    "\n",
    "def custom_result(fn):\n",
    "    results = [read_preds_file(fn)]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nusc_results(det_annos, **kwargs):\n",
    "    nusc_annos = transform_det_annos_to_nusc_annos(det_annos, nusc)\n",
    "    nusc_annos['meta'] = {\n",
    "        'use_camera': False,\n",
    "        'use_lidar': True,\n",
    "        'use_radar': False,\n",
    "        'use_map': False,\n",
    "        'use_external': False,\n",
    "    }\n",
    "\n",
    "    output_path = Path(kwargs['output_path'])\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "    res_path = str(output_path / 'results_nusc.json')\n",
    "    with open(res_path, 'w') as f:\n",
    "        json.dump(nusc_annos, f)\n",
    "    \n",
    "    print('The predictions of NuScenes have been saved to {res_path}')\n",
    "    return output_path, res_path\n",
    "\n",
    "def get_metrics(output_path, res_path):\n",
    "    eval_set_map = {\n",
    "        'v1.0-mini': 'mini_val',\n",
    "        'v1.0-trainval': 'val',\n",
    "        'v1.0-test': 'test'\n",
    "    }\n",
    "    try:\n",
    "        eval_version = 'detection_cvpr_2019'\n",
    "        eval_config = config_factory(eval_version)\n",
    "    except:\n",
    "        eval_version = 'cvpr_2019'\n",
    "        eval_config = config_factory(eval_version)\n",
    "\n",
    "    nusc_eval = NuScenesEval(\n",
    "        nusc,\n",
    "        config=eval_config,\n",
    "        result_path=res_path,\n",
    "        eval_set=eval_set_map['v1.0-mini'],\n",
    "        output_dir=str(output_path),\n",
    "        verbose=True,\n",
    "    )\n",
    "    metrics_summary = nusc_eval.main(plot_examples=0, render_curves=False)\n",
    "\n",
    "    with open(output_path / 'metrics_summary.json', 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    return metrics, metrics_summary, nusc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(results):\n",
    "    return [\n",
    "        result\n",
    "        for result in results\n",
    "        if result['metadata']['token'] in mini_val_tokens\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_token_dict()\n",
    "results = read_results()\n",
    "results = filter_results(results)\n",
    "nusc_results = transform_det_annos_to_nusc_annos(results, nusc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "The predictions of NuScenes have been saved to {res_path}\n",
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from /home/ranai/nuscenes_dataset/3D_Detection/results_nusc.json. Found detections for 81 samples.\n",
      "Loading annotations for mini_val split from nuScenes version: v1.0-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 269.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 81 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 905\n",
      "=> After distance based filtering: 905\n",
      "=> After LIDAR and RADAR points based filtering: 905\n",
      "=> After bike rack filtering: 905\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 4441\n",
      "=> After distance based filtering: 3785\n",
      "=> After LIDAR and RADAR points based filtering: 3393\n",
      "=> After bike rack filtering: 3393\n",
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Saving metrics to: /home/ranai/nuscenes_dataset/3D_Detection\n",
      "mAP: 0.0755\n",
      "mATE: 0.8586\n",
      "mASE: 0.8272\n",
      "mAOE: 0.8025\n",
      "mAVE: 1.2312\n",
      "mAAE: 0.8557\n",
      "NDS: 0.1034\n",
      "Eval time: 1.2s\n",
      "\n",
      "Per-class results:\n",
      "Object Class        \tAP    \tATE   \tASE   \tAOE   \tAVE   \tAAE   \n",
      "car                 \t0.361 \t0.175 \t0.151 \t0.178 \t0.364 \t0.072 \n",
      "truck               \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
      "bus                 \t0.394 \t0.411 \t0.121 \t0.045 \t3.486 \t0.773 \n",
      "trailer             \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
      "construction_vehicle\t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
      "pedestrian          \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
      "motorcycle          \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
      "bicycle             \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
      "traffic_cone        \t0.000 \t1.000 \t1.000 \tnan   \tnan   \tnan   \n",
      "barrier             \t0.000 \t1.000 \t1.000 \t1.000 \tnan   \tnan   \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(nusc_results))\n\u001b[1;32m      2\u001b[0m output_path, res_path \u001b[38;5;241m=\u001b[39m save_nusc_results(results, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ranai/nuscenes_dataset/3D_Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m metrics, metrics_summary \u001b[38;5;241m=\u001b[39m get_metrics(output_path, res_path)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print(len(nusc_results))\n",
    "output_path, res_path = save_nusc_results(results, output_path=\"/home/ranai/nuscenes_dataset/3D_Detection\")\n",
    "metrics, metrics_summary = get_metrics(output_path, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
