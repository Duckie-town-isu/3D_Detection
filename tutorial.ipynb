{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repository Demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a flowchart for the actions that the tool takes.\n",
    "\n",
    "Each of the following blocks are described in more detail through this notebook. Feel free to change parameters and experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"figures/drawio_flowchart.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Ensure setup is accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 System Requirements for TRELPy\n",
    "- OS: Ubuntu (Has been tested to work on Ubuntu 20.04)\n",
    "- Computer with GPU to run inference\n",
    "\n",
    "\n",
    "### 1.1.2. Uncomment and run the following scripts to install all the pip and apt dependencies\n",
    "```bash\n",
    "pip3 install -r pip-requirements.txt &&\n",
    "sudo apt-get -y update &&\n",
    "sed 's/#.*//' apt-requirements.txt | xargs sudo apt-get -y install\n",
    "```\n",
    "\n",
    "\n",
    "### 1.1.3. Ensure all the following programs are installed.\n",
    "\n",
    "|Name and link of program|What kind of installation| Versions tested on |\n",
    "|-|-|-|\n",
    "| [CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html) | Local, Docker | cuda_12.4.r12.4 |\n",
    "| [STORM](https://www.stormchecker.org/documentation/obtain-storm/build.html) | Local | - |\n",
    "| [PyTorch](https://pytorch.org/get-started/locally/) | Local | 2.1.0+cu12 |\n",
    "| [StormPy](https://moves-rwth.github.io/stormpy/installation.html) | Local |  |\n",
    "| [TuLiP](https://github.com/tulip-control/tulip-control) |  Local |  |\n",
    "| [MMDetection3D](https://mmdetection3d.readthedocs.io/en/latest/get_started.html) | Local |  |\n",
    "| [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) | Local, Docker | 1.14.6 |\n",
    "| [PRISM (Optional)](https://www.prismmodelchecker.org/manual/InstallingPRISM/Instructions) | Local |  |\n",
    "\n",
    "**Local** means you are running on your ubuntu installation \\\n",
    "**Docker** means you will be using the provided Dockerfile. *This is currently a work in progress and not completely setup.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Testing installation validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dataset_version' from partially initialized module 'config' (most likely due to a circular import) (/home/ranai/nuscenes_dataset/3D_Detection/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chain, combinations\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple, Dict, Any, List\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfusion_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrix\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerate_confusion_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerateConfusionMatrix\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/nuscenes_dataset/3D_Detection/confusion_matrix.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chain, combinations\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpowerset\u001b[39m(s: \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/nuscenes_dataset/3D_Detection/config.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#! /usr/bin/python3\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrelpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_imports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_dir_if_not_exist\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "File \u001b[0;32m~/nuscenes_dataset/3D_Detection/src/trelpy/common_imports.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnuscenes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnuscenes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NuScenes\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_version, dataset_root\n\u001b[1;32m      7\u001b[0m now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m      8\u001b[0m time_at_run \u001b[38;5;241m=\u001b[39m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'dataset_version' from partially initialized module 'config' (most likely due to a circular import) (/home/ranai/nuscenes_dataset/3D_Detection/config.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from pyquaternion import Quaternion\n",
    "from itertools import chain, combinations\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from confusion_matrix import ConfusionMatrix\n",
    "from generate_confusion_matrix import GenerateConfusionMatrix\n",
    "\n",
    "import torch\n",
    "\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.common.config import config_factory\n",
    "from nuscenes.eval.common.data_classes import EvalBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Setting up datasets\n",
    "\n",
    "The NuScenes dataset can be downloaded from [this link after logging in](https://www.nuscenes.org/nuscenes#download:~:text=Show%20more%20%E2%86%93-,Downloads,-Here%20we%20list). \\\n",
    "Instructions for setting up nuscenes for working with MMDetection3D can be found at [MMDetection3D Dataset Preperation](https://mmdetection3d.readthedocs.io/en/latest/user_guides/dataset_prepare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Getting setup for running inference\n",
    "\n",
    "In this step, you will download and install a model so that you can begin running inference on the dataset you downloaded. \\\n",
    "\\\n",
    "**Config File** is a python file that contains parameters such as batch size, list of classes, indices, input size, etc.   \n",
    "**Checkpoint File** is a `.pth` file which contains a the exact values of all parameters (weights, current learning rate, etc.) and stores all of this in non-volatile memory.\n",
    "\n",
    "| Model Name | Modality |Link to Checkpoint file | Link to Config file | mAP (%) | Accuracy (%) | Link to paper |\n",
    "|-|-|-|-|-|-|-|\n",
    "|NuScenes SECFPN|Lidar|[Backbone file](https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d_20210826_225857-f19d00a3.pth)|[Config File](https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_secfpn_sbn-all_8xb4-2x_nus-3d.py)|34.33|49.1|[PointPillars](https://arxiv.org/abs/1812.05784)|\n",
    "|NuScenes SECFPN(FP16)|Lidar|[Backbone file](https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_secfpn_sbn-all_8xb2-amp-2x_nus-3d.py)|[Config file](https://download.openmmlab.com/mmdetection3d/v0.1.0_models/fp16/hv_pointpillars_secfpn_sbn-all_fp16_2x8_2x_nus-3d/hv_pointpillars_secfpn_sbn-all_fp16_2x8_2x_nus-3d_20201020_222626-c3f0483e.pth)|35.19|50.27|[PointPillars](https://arxiv.org/abs/1812.05784)|\n",
    "|NuScenes FPN|Lidar|[Backbone file](https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_fpn_sbn-all_8xb4-2x_nus-3d.py)|[Config File](https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20210826_104936-fca299c1.pth)|39.7|53.2|[PointPillars](https://arxiv.org/abs/1812.05784)|\n",
    "|NuScenes FPN (FP16)|Lidar|[Backbone file](https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_fpn_sbn-all_8xb2-amp-2x_nus-3d.py)|[Config file](https://download.openmmlab.com/mmdetection3d/v0.1.0_models/fp16/hv_pointpillars_fpn_sbn-all_fp16_2x8_2x_nus-3d/hv_pointpillars_fpn_sbn-all_fp16_2x8_2x_nus-3d_20201021_120719-269f9dd6.pth)|39.2|53.2|[PointPillars](https://arxiv.org/abs/1812.05784)|\n",
    "|-|-|-|-|-|-|-|\n",
    "|BEVFusion|Lidar + Camera|[Backbone file](https://github.com/open-mmlab/mmdetection3d/blob/fe25f7a51d36e3702f961e198894580d83c4387b/projects/BEVFusion/configs/bevfusion_lidar_voxel0075_second_secfpn_8xb4-cyclic-20e_nus-3d.py)|[Config file](https://download.openmmlab.com/mmdetection3d/v1.1.0_models/bevfusion/bevfusion_lidar_voxel0075_second_secfpn_8xb4-cyclic-20e_nus-3d-2628f933.pth)|69.6|64.9|[BEVFusion](https://arxiv.org/abs/2205.13542)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Setup your custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains content of the file `custom_env.py`. This is a configuration file that stores path variables, code parameters, etc. Once you fill out the following cell and run this notebook to ensure accuracy of this file, move the contents of this file to `custom_env.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## PARMS #########\n",
    "## Inference model params ##\n",
    "model_name = \"model2_good\"  # The name of the directory where the ML model for inference is stored\n",
    "modality = \"lidar\"          # The modality of the data\n",
    "is_mini = True              # Are you using this on NuScenes Mini?\n",
    "\n",
    "## Confusion Matrix Generation Params ##\n",
    "verbose = True\n",
    "###### PARAMS END ######\n",
    "\n",
    "\n",
    "####### Configuring the right dataset ########\n",
    "# The code looks in mmdetection3d/data/ for a dataset folder or symlink called `dataset` to find a dataset with size `size`.\n",
    "# The results will be stored in inside a folder titled `inference_results_path`\n",
    "if is_mini:\n",
    "    dataset = \"nuscenes-mini\"   \n",
    "    size = \"mini\"\n",
    "else:\n",
    "    dataset = \"nuscenes-full\"\n",
    "    size= \"full\"\n",
    "    \n",
    "########### METHODS #############\n",
    "def getGitRoot():\n",
    "    \"\"\"Gets the root directory of the git repository\n",
    "\n",
    "    Returns:\n",
    "        str: path the denotes the root directory of the git repository\n",
    "    \"\"\"\n",
    "    return subprocess.Popen(['git', 'rev-parse', '--show-toplevel'], stdout=subprocess.PIPE).communicate()[0].rstrip().decode('utf-8')\n",
    "\n",
    "def create_dir_if_not_exist(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        print(f\"Directory {dir_path} not found. Creating...\")\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        print(f\"Not creating {dir_path} because it already exists\")\n",
    "\n",
    "def is_set_to_mini():\n",
    "    return is_mini\n",
    "###### METHODS END #########\n",
    "\n",
    "\n",
    "home_dir = str(Path.home())\n",
    "repo_dir = f\"{home_dir}/nuscenes_dataset/3D_Detection\"  #................# The directory where the repo is stored\n",
    "dataset_root = f\"{home_dir}/software/mmdetection3d/data/{dataset}/\"  #...# The directory where the dataset is stored\n",
    "output_dir = f\"{home_dir}/inference_results/{dataset}/{model_name}\" #..............# The directory where the output of inference will be stored\n",
    "model_dir  = f\"{output_dir}/{model_name}\" #..............................# The directory where the inference model is stored\n",
    "preds_dir  = f\"{model_dir}/preds\" #......................................# The directory where inference predictions are stored\n",
    "cm_dir = f\"{repo_dir}/saved_cms/{modality}/{size}/{model_name}\" #........# The directory where the confusion matrices generated by the tool will be stored \n",
    "create_dir_if_not_exist(cm_dir)\n",
    "\n",
    "###########################\n",
    "### Standard Parameters ###\n",
    "eval_set_map = {\n",
    "        'v1.0-mini': 'mini_val',\n",
    "        'v1.0-trainval': 'val',\n",
    "        'v1.0-test': 'test'\n",
    "    }\n",
    "\n",
    "dataset_version = 'v1.0-mini' if is_set_to_mini() else 'v1.0-trainval'\n",
    "\n",
    "try:\n",
    "    eval_version = 'detection_cvpr_2019'\n",
    "    eval_config = config_factory(eval_version)\n",
    "except:\n",
    "    eval_version = 'cvpr_2019'\n",
    "    eval_config = config_factory(eval_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Ensure NuScenes is setup correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############# IMPORTS #############\n",
    "## Usually you would use the following imports to get all necessary paths from the custom_env.py file\n",
    "\n",
    "# from custom_env import dataset_root as dataroot\n",
    "# from custom_env import cm_dir, model_dir, eval_version, eval_config\n",
    "# from custom_env import is_set_to_mini, eval_set_map, dataset_version, eval_version \n",
    "##################################\n",
    "\n",
    "# parameters to setup nuScenes\n",
    "\n",
    "nusc = NuScenes(version=dataset_version, dataroot = dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To run inference, change line 3 to `if True:`\n",
    "\n",
    "if False:\n",
    "    now = datetime.now()\n",
    "    configs_path = \"configs/pointpillars/pointpillars_hv_fpn_sbn-all_8xb4-2x_nus-3d.py\"\n",
    "    checkpoint_path = \"checkpoints/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20210826_104936-fca299c1.pth\"\n",
    "\n",
    "    folder_name = \"model_\"+now.strftime(\"%m-%d-%Y_%H_%M\")\n",
    "    out_dir = f\"{output_dir}/\" + folder_name\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    info_file = os.path.join(out_dir, \"model_info.txt\")\n",
    "    with open(info_file, 'w') as f:\n",
    "        f.write(f\"configs_path = {configs_path} \\n checkpoint_path = {checkpoint_path} \\n\")\n",
    "    f.close()\n",
    "        \n",
    "    pcd_path = f\"{dataset_root}/samples/LIDAR_TOP/\"\n",
    "\n",
    "    pcd_list = os.listdir(pcd_path)\n",
    "    print(len(pcd_list))\n",
    "\n",
    "    for i, pcd in enumerate(pcd_list):\n",
    "        path = Path(f\"{pcd_path}/{pcd}\").absolute()\n",
    "        if path.exists():\n",
    "            cmd = f'python3 demo/pcd_demo.py {str(path)} {configs_path} {checkpoint_path} --device cuda --out-dir {out_dir}'\n",
    "        \n",
    "        ##### Uncomment this to run the inference ######    \n",
    "        subprocess.run(cmd, cwd=f\"{home_dir}/software/mmdetection3d/\", shell=True)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f\"---- ---- !-!-!-!- run_inference.py: Done with {i} files\")\n",
    "\n",
    "    with open(info_file, 'a') as f:\n",
    "        f.write(f\"Inferences complete.\")\n",
    "    f.close()\n",
    "\n",
    "    print(f\"Inference complete. Output written to {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Confusion Matrix Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Setup \n",
    "\n",
    "In the following block, there are various variables that you can change to change the behavior of the Confusion Matrix Generation\n",
    "\n",
    "| Variable name | Type | Description |\n",
    "|--|--|--|\n",
    "| `list of classes` | `list` | The class labels for the confsion matrix |\n",
    "|`conf_mat_mapping`|`dict`| Dict ***keys*** represent output classes for inference |\n",
    "|`conf_mat_mapping`|`dict`| Dict ***values*** represent the class lable to match it with|\n",
    "| `labels` | `dict` | Dict ***keys*** represent place in the confusion matrix |\n",
    "| `labels` | `dict` | Dict ***values*** represent place in the confusion matrix   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"figures/Distance_param.jpg\" width=550px height=600px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_classes = [\"ped\", \"obs\"]        # The classes that are to be considered for the confusion matrix\n",
    "\n",
    "PED = 0\n",
    "OBS = 1\n",
    "EMPTY = 2\n",
    "                                        # TODO\n",
    "labels = {0: \"ped\", 1: \"obs\", 2:\"empty\"}\n",
    "\n",
    "conf_mat_mapping = {                    # The mapping from the output of the model to the classes in the confusion matrix\n",
    "    \"pedestrian\": PED,\n",
    "    \"bus\": OBS,\n",
    "    \"car\" : OBS,\n",
    "    \"truck\": OBS,\n",
    "    \"bicycle\": OBS,\n",
    "    \"motorcycle\": OBS,\n",
    "    \"traffic_cone\": OBS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GenerateConfusionMatrix(nusc=nusc,      \n",
    "    config=eval_config,\n",
    "    result_path=f'{model_dir}/results_nusc.json',   ## PARAM Where are the results are stored\n",
    "    eval_set=eval_set_map[dataset_version],\n",
    "    output_dir=os.getcwd(), #.......................## PARAM Where to store the output\n",
    "    verbose=verbose,  #.............................## PARAM Verbose\n",
    "    conf_mat_mapping=conf_mat_mapping,\n",
    "    list_of_classes=list_of_classes,\n",
    "    distance_parametrized=True,\n",
    "    max_dist=100, #................................## PARAM The maximum distance the model considers\n",
    "    distance_bin=10 #..............................## PARAM For distance parametrized confusion matrices, the distance between radius bands\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Visualizing the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### RENDERING LIBRARIES ######\n",
    "\n",
    "from nuscenes_render import render_sample_data_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed = 42\n",
    "\n",
    "sample_tokens = generator.gt_boxes.sample_tokens # All the sample tokens in the dataset\n",
    "\n",
    "tok = random.choice(sample_tokens)\n",
    "sample_data_token = nusc.get('sample', tok)['data']['LIDAR_TOP']\n",
    "\n",
    "print(f\"--------- Details for sample {tok} ------------\")\n",
    "print(f\"Number of ground truth objects {len(generator.gt_boxes[tok])}\")\n",
    "print(f\"Number of prediction objects {len(generator.pred_boxes[tok])}\")\n",
    "\n",
    "render_sample_data_with_predictions(nusc=nusc, \n",
    "                                    sample_token=sample_data_token, \n",
    "                                    gt_boxes=generator.gt_boxes[tok], \n",
    "                                    pred_boxes=generator.pred_boxes[tok], \n",
    "                                    verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for probability plot generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Does the env have a ped? empty? AND the user can set VMAX, Ncar \n",
    "# We generate probabilitie based on that\n",
    "# cb_cm_ped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "```latex\n",
    "@inproceedings{PointPillars,\n",
    "  title={Pointpillars: Fast encoders for object detection from point clouds},\n",
    "  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},\n",
    "  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n",
    "  pages={12697--12705},\n",
    "  year={2019}\n",
    "}\n",
    "```\n",
    "\n",
    "```latex\n",
    "@inproceedings{BevFusion,\n",
    "  title={BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation},\n",
    "  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xingyu and Mao, Huizi and Rus, Daniela and Han, Song},\n",
    "  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n",
    "  year={2023}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
