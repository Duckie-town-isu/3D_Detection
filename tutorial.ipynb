{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repository Demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a flowchart for the actions that the tool takes.\n",
    "\n",
    "Each of the following blocks are described in more detail through this notebook. Feel free to change parameters and experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"flowchart.drawio.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Ensure setup is accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip3 install -r pip-requirements.txt\n",
    "sed 's/#.*//' apt-requirements.txt | xargs sudo apt-get install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from itertools import chain, combinations\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from confusion_matrix import ConfusionMatrix\n",
    "from generate_confusion_matrix import GenerateConfusionMatrix\n",
    "\n",
    "\n",
    "from custom_env import home_dir, cm_dir, repo_dir, output_dir, preds_dir, model_dir, is_set_to_mini\n",
    "\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.common.config import config_factory\n",
    "from nuscenes.eval.common.data_classes import EvalBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Setup custom_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for setting up nuscenes can be found at [MMDetection3D Dataset Preperation](https://mmdetection3d.readthedocs.io/en/latest/user_guides/dataset_prepare.html)\n",
    "\n",
    "The following cell needs to be filled out. This file is your custom environemnt and defines where things are located and whenere outputs should go. If you choose to run the tool with `verbose = True`, outputs of certain files might be placed in these locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## PARMS #########\n",
    "## ONLY Change model_name here to make it work with your version.\n",
    "model_name = \"model2_good\"  # The name of the directory where the ML model for inference is stored\n",
    "modality = \"lidar\"          # The modality of the data\n",
    "is_mini = True              # Are you using this on NuScenes Mini?\n",
    "\n",
    "## Configure the name of the dataset\n",
    "if is_mini:\n",
    "    dataset = \"nuscenes-mini\"\n",
    "    size = \"mini\"\n",
    "    inf_res = \"inference_results_mini\"\n",
    "else:\n",
    "    dataset = \"nuscenes-full\"\n",
    "    size= \"full\"\n",
    "    inf_res = \"inference_results\"\n",
    "    \n",
    "########################\n",
    "#### Get Repo Root #####\n",
    "def getGitRoot():\n",
    "    return subprocess.Popen(['git', 'rev-parse', '--show-toplevel'], stdout=subprocess.PIPE).communicate()[0].rstrip().decode('utf-8')\n",
    "\n",
    "def create_dir_if_not_exist(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        print(f\"Directory {dir_path} not found. Creating...\")\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        print(f\"Not creating {dir_path} because it already exists\")\n",
    "\n",
    "def is_set_to_mini():\n",
    "    return is_mini\n",
    "\n",
    "\n",
    "home_dir = str(Path.home())\n",
    "repo_dir = f\"{home_dir}/nuscenes_dataset/3D_Detection\"                 # The directory where the repo is stored\n",
    "dataset_root = f\"{home_dir}/software/mmdetection3d/data/{dataset}/\"    # The directory where the dataset is stored\n",
    "output_dir = f\"{home_dir}/nuscenes_dataset/{inf_res}\"                  # The directory where the output of inference will be stored\n",
    "model_dir  = f\"{output_dir}/{model_name}\"                              # The directory where the inference model is stored\n",
    "preds_dir  = f\"{model_dir}/preds\"                                      # The directory where inference predictions are stored\n",
    "cm_dir = f\"{repo_dir}/saved_cms/{modality}/{size}/{model_name}\"        # The directory where the confusion matrices generated by the tool will be stored \n",
    "create_dir_if_not_exist(cm_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensure NuScenes is setup correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_env import dataset_root as dataroot\n",
    "from custom_env import cm_dir, model_dir, eval_version, eval_config\n",
    "from custom_env import is_set_to_mini, eval_set_map, dataset_version, eval_version \n",
    "\n",
    "# parameters to setup nuScenes\n",
    "\n",
    "nusc = NuScenes(version=dataset_version, dataroot = dataroot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting setup for running inference\n",
    "\n",
    "**Config File** is a python file that contains parameters such as batch size, list of classes, indices, input size, etc.   \n",
    "**Checkpoint File** is a `.pth` file which contains a the exact values of all parameters (weights, current learning rate, etc.) and stores all of this in non-volatile memory.\n",
    "\n",
    "| Model Name | Modality |Link to Checkpoint file | Link to Config file | mAP (%) | Accuracy (%) | Link to paper |\n",
    "|-|-|-|-|-|-|-|\n",
    "|NuScenes SECFPN|Lidar|[Backbone file](https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d_20210826_225857-f19d00a3.pth)|[Config File](https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_secfpn_sbn-all_8xb4-2x_nus-3d.py)|34.33|49.1|[PointPillars](https://arxiv.org/abs/1812.05784)|\n",
    "|NuScenes SECFPN(FP16)|Lidar|[Backbone file](https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_secfpn_sbn-all_8xb2-amp-2x_nus-3d.py)|[Config file](https://download.openmmlab.com/mmdetection3d/v0.1.0_models/fp16/hv_pointpillars_secfpn_sbn-all_fp16_2x8_2x_nus-3d/hv_pointpillars_secfpn_sbn-all_fp16_2x8_2x_nus-3d_20201020_222626-c3f0483e.pth)|35.19|50.27|[PointPillars](https://arxiv.org/abs/1812.05784)|\n",
    "|-|-|-|-|-|-|-|\n",
    "|BEVFusion|Lidar + Camera|[Backbone file](https://github.com/open-mmlab/mmdetection3d/blob/fe25f7a51d36e3702f961e198894580d83c4387b/projects/BEVFusion/configs/bevfusion_lidar_voxel0075_second_secfpn_8xb4-cyclic-20e_nus-3d.py)|[Config file](https://download.openmmlab.com/mmdetection3d/v1.1.0_models/bevfusion/bevfusion_lidar_voxel0075_second_secfpn_8xb4-cyclic-20e_nus-3d-2628f933.pth)|69.6|64.9|[BEVFusion](https://arxiv.org/abs/2205.13542)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "configs_path = \"configs/pointpillars/pointpillars_hv_fpn_sbn-all_8xb4-2x_nus-3d.py\"\n",
    "checkpoint_path = \"checkpoints/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20210826_104936-fca299c1.pth\"\n",
    "TAG = \"xyz model run\"\n",
    "\n",
    "folder_name = \"model_\"+now.strftime(\"%m-%d-%Y_%H_%M\")\n",
    "out_dir = f\"{output_dir}\" + folder_name\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "info_file = os.path.join(out_dir, \"model_info.txt\")\n",
    "with open(info_file, 'w') as f:\n",
    "    f.write(f\"configs_path = {configs_path} \\n checkpoint_path = {checkpoint_path} \\n\")\n",
    "f.close()\n",
    "    \n",
    "pcd_path = f\"{dataset_root}/samples/LIDAR_TOP/\"\n",
    "\n",
    "pcd_list = os.listdir(pcd_path)\n",
    "print(len(pcd_list))\n",
    "\n",
    "for i, pcd in enumerate(pcd_list):\n",
    "    path = Path(f\"{pcd_path}/{pcd}\").absolute()\n",
    "    if path.exists():\n",
    "        cmd = f'python3 demo/pcd_demo.py {str(path)} {configs_path} {checkpoint_path} --device cuda --out-dir {out_dir}'\n",
    "    \n",
    "    ##### Uncomment this to run the inference #####    \n",
    "    # subprocess.run(cmd, cwd=f\"{home_dir}/software/mmdetection3d/\", shell=True)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(f\"---- ---- !-!-!-!- run_inference.py: Done with {i} files\")\n",
    "\n",
    "with open(info_file, 'a') as f:\n",
    "    f.write(f\"Inferences complete.\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup for confusion matrix generation\n",
    "\n",
    "| Variable name | Type | Description |\n",
    "|--|--|--|\n",
    "| `list of classes` | `list` | The class labels for the confsion matrix |\n",
    "|`conf_mat_mapping`|`dict`| Dict ***keys*** represent output classes for inference |\n",
    "|`conf_mat_mapping`|`dict`| Dict ***values*** represent the class lable to match it with|\n",
    "| `labels` | `dict` | Dict ***keys*** represent place in the confusion matrix |\n",
    "| `labels` | `dict` | Dict ***values*** represent place in the confusion matrix   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_classes = [\"ped\", \"obs\"]\n",
    "\n",
    "PED = 0\n",
    "OBS = 1\n",
    "EMPTY = 2\n",
    "\n",
    "labels = {0: \"ped\", 1: \"obs\", 2:\"empty\"}\n",
    "\n",
    "conf_mat_mapping = {\n",
    "    \"pedestrian\": PED,\n",
    "    \"bus\": OBS,\n",
    "    \"car\" : OBS,\n",
    "    \"truck\": OBS,\n",
    "    \"bicycle\": OBS,\n",
    "    \"motorcycle\": OBS,\n",
    "    \"traffic_cone\": OBS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GenerateConfusionMatrix(nusc=nusc,      \n",
    "    config=eval_config,\n",
    "    result_path=f'{model_dir}/results_nusc.json',   ## PARAM Where are the results are stored\n",
    "    eval_set=eval_set_map[dataset_version],\n",
    "    output_dir=os.getcwd(), #.......................## PARAM Where to store the output\n",
    "    verbose=False,  #...............................## PARAM Verbose\n",
    "    conf_mat_mapping=conf_mat_mapping,\n",
    "    list_of_classes=list_of_classes,\n",
    "    distance_parametrized=True,\n",
    "    max_dist=100, #................................## PARAM The maximum distance the model considers\n",
    "    distance_bin=10 #..............................## PARAM For distance parametrized confusion matrices, the distance between radius bands\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for probability plot generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Does the env have a ped? empty? AND the user can set VMAX, Ncar \n",
    "# We generate probabilitie based on that\n",
    "# cb_cm_ped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "```latex\n",
    "@inproceedings{PointPillars,\n",
    "  title={Pointpillars: Fast encoders for object detection from point clouds},\n",
    "  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},\n",
    "  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n",
    "  pages={12697--12705},\n",
    "  year={2019}\n",
    "}\n",
    "```\n",
    "\n",
    "```latex\n",
    "@inproceedings{BevFusion,\n",
    "  title={BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation},\n",
    "  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xingyu and Mao, Huizi and Rus, Daniela and Han, Song},\n",
    "  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n",
    "  year={2023}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
